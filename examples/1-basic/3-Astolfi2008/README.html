<!DOCTYPE html><html>

<head>
<meta charset="utf-8">
<title>README</title>
<style type="text/css">
html{
	font-family: Lato;
	font-size: 20px;
}	

body {
	font-family: Lato, Helvetica, Arial, sans-serif;
	padding:1em;
	margin:auto;
	max-width:42em;
}

h1, h2, h3, h4, h5, h6 {
	font-weight: bold;
}

h1 {
	color: #000000;
	font-size: 28pt;
}

h2 {
	border-bottom: 1px solid #CCCCCC;
	color: #000000;
	font-size: 24px;
}

h3 {
	font-size: 18px;
}

h4 {
	font-size: 16px;
}

h5 {
	font-size: 14px;
}

h6 {
	color: #777777;
	background-color: inherit;
	font-size: 14px;
}

hr {
	height: 0.2em;
	border: 0;
	color: #CCCCCC;
	background-color: #CCCCCC;
}

p, blockquote, ul, ol, dl, li, table, pre {
	margin: 15px 0;
}

a, a:visited {
	color: #4183C4;
	background-color: inherit;
	text-decoration: none;
}

#message {
	border-radius: 6px;
	border: 1px solid #ccc;
	display:block;
	width:100%;
	height:60px;
	margin:6px 0px;
}

button, #ws {
	font-size: 10pt;
	padding: 4px 6px;
	border-radius: 5px;
	border: 1px solid #bbb;
	background-color: #eee;
}

code, pre, #ws, #message {
	font-family: Monaco;
	font-size: 10pt;
	border-radius: 3px;
	background-color: #F8F8F8;
	color: inherit;
}

code {
	border: 1px solid #EAEAEA;
	margin: 0 2px;
	padding: 0 5px;
}

pre {
	border: 1px solid #CCCCCC;
	overflow: auto;
	padding: 4px 8px;
}

pre > code {
	border: 0;
	margin: 0;
	padding: 0;
}

#ws { background-color: #f8f8f8; }

.send { color:#77bb77; }
.server { color:#7799bb; }
.error { color:#AA0000; }
</style>
</head>
<body>
<h1 id="toc_0">Astolfi2008</h1>

<p>Astolfi, Laura et al. &quot;Tracking the time-varying cortical connectivity patterns by adaptive multivariate estimators&quot;</p>

<h2 id="toc_1">Description</h2>

<p>In this folder you have a <code>generateresults.m</code> script for performing the estimation procedures and then save the results in a <code>.mat</code> file. The <code>generatefigures.m</code> script loads the previous results and plots the relevant figures.</p>

<p>My goal here is to reproduce the toy model in Laura Astolfi&#39;s article from 2008, where she studies the performance of a recursive least-squares algorithm (RLS) in the tracking of neural connectivity. The example is a three channel one, which is not a MVAR process <em>per se</em>, but can be well modelled by one. In fact, we have the following equations</p>

<p>\[\left\{\begin{array}{lll}
x_{1}(n) &amp;=&amp; s(n) + w_{1}(n) \\
x_{2}(n) &amp;=&amp; 0.6x_{1}(n-1) + w_{2}(n) \\
x_{3}(n) &amp;=&amp; a_{31}x_{1}(n-2) + 0.7x_{2}(n-1) + w_{3}(n)
\end{array}\right.\]</p>

<p>where \(s(n)\) is a simulated EEG signal generated by a neural mass model. The coefficient \(a_{31}\) is equal to 0.0 at first but then is switched to 0.9 at \(n = n_{\text{switch}}\). The \(w_{i}(n)\) are white Gaussian noise with variances fixed according to some desired SNR.</p>

<p>The connections of this toy model can be summarized in the following graph</p>

<div style="text-align: center;"><img src="./diagram.svg" align="middle" width="290"></div>

<p>Besides reproducing the results in Astolfi&#39;s article, I also wanted to show that a sliding-window algorithm is capable of giving the same results as the RLS, as well as allowing us to perform statistical significance tests on the estimates&#39; values.</p>

<p>During the estimations, we consider \(N_{S} = 450\) samples and \(N_{T} = 80\) trials. Both the SW and RLS algorithms are capable of estimating a joint model for these multiple trials.</p>

<h2 id="toc_2">Figure 1</h2>

<p>Here below you see the power spectral density of the input signal \(s(n)\), which was generated by a neural mass model tuned to simulate EEG signals at the alpha band.</p>

<div style="text-align: center;"><img src="./figure1.svg" align="middle" width="350"></div>

<p><br></p>

<p>PSD&#39;s peak at \(\simeq 14\) Hz and its \(1/f\) decay confirms that the input signal is indeed oscillating at the alpha band with a very similar behavior that what one would expect in EEG signals.</p>

<h2 id="toc_3">Figure 2</h2>

<p>To form a time-frequency map for the PDC between each pair of channels, we rely on a two-step procedure:</p>

<div><pre><code class="language-none">1. Estimate a MVAR model for each time instant n
2. From the matrix coefficients of this MVAR model, estimate the PDC at n</code></pre></div>

<p>As already mentioned, two options are possible for estimating the MVAR models: a sliding-window approach or a RLS algorithm. The RLS algorithm is much faster than the sliding-window procedure, but it lacks the possibility of calculating thresholds for statistical significance of the estimated PDC values. Moreover, the idea of a forgetting factor in the RLS is not as intuitive as that of sliding-window, whose size can be readily associated to the expected resolution in the time-frequency representation.</p>

<p>Here below I plot the time-frequency representations for the PDC between channels using the RLS algorithm with a forgetting factor \(C = 0.05\).</p>

<div style="text-align: center;"><img src="./figure2-RLS.svg" align="middle" width="600"></div>

<p><br></p>

<p>The next figure portrays the time-frequency representations for the PDC between channels using the SW algorithm with a window of \(L = 32\) points.</p>

<div style="text-align: center;"><img src="./figure2-SW.svg" align="middle" width="600"></div>

<p><br></p>

<p>Note that the results with both procedures are pratically the same (to be honest, I can hardly see any difference).</p>

<p>As mentioned before, the \(a_{31}\) coefficient is turned on at \(n = 225\), and we can see that the  \(\pi_{31}\)&#39;s time-frequency representation with both algorithms effectively tracks this change. Additionaly, we can see that the autospectrum (or power) at channel 3 suddenly increases when the connection from 1 to 3 is turned on.</p>

<h2 id="toc_4">Figure 3</h2>

<p>It&#39;s always nice to see a &quot;slice&quot; of the previous time-frequency representations so as to check how the PDC values at one given frequency evolve through time. In the figure below, I compare the results for \(\pi_{31}\) with SW (blue) and RLS (red) at the frequency \(f = 14.22\) Hz.</p>

<div style="text-align: center;"><img src="./figure3.svg" align="middle" width="380"></div>

<p><br></p>

<p>Obviously, if one changes the forgetting factor \(C\) or the sliding-window size \(L\), the transition from off to on state in the graph will change too.</p>

<h2 id="toc_5">Conclusion</h2>

<p>The previous figures show a situation where the change of a coefficient in the MVAR process generating \({\bf x}(n)\) leads to a change in the network structure of the multichannel recording. Estimations with a sliding-window and the RLS algorithm give similar results, as shown in the time-frequency maps. However, it should be noted that we don&#39;t know of any published results showing a procedure for assessing the statistical significance of the estimated PDCs when using the RLS algorithm, whereas for the SW approach we have proposed one (see ../../embc2016 for more information).   </p>

<script type="text/x-mathjax-config">
if (typeof MathJaxListener !== 'undefined') {
  MathJax.Hub.Register.StartupHook('End', function () {
    MathJaxListener.invokeCallbackForKey_('End');
  });
}
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
